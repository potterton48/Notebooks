{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1KE8lLrpEVjOjq2jN+lj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/potterton48/Notebooks/blob/main/TPD_Workshop1_ML_Training_Set_Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop 1: Find if a PDB is seen in the training set of RosettaFoldTTA All-Atom (or any model trained on the PDB)\n",
        "Steps of the protocol:\n",
        "1. Take PDBs from previous exercise (to begin with you may want to run through the example\n",
        "2. Check if PDB ID is in training list\n",
        "3. Download fasta file of sequence from PDB\n",
        "4. Search sequence similarity of query sequence to the training set\n",
        "5. (Extension) Try to find structure similarity of protein to training set."
      ],
      "metadata": {
        "id": "df2WR_So74md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We need to install some packages, this may take around 1-2 minutes to complete.**"
      ],
      "metadata": {
        "id": "N9yVVxZQ11lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation\n",
        "!apt install hmmer  # like blast for fast sequence database searching\n",
        "!pip install pandas\n",
        "!pip install gdown  # for downloading a file from google drive\n",
        "!pip install biopython  # used for handling sequences and pdb files\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install bioconda::mafft # to do MSA"
      ],
      "metadata": {
        "id": "qq3jfMwNI0z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO2p7Ts87Aav"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from Bio.SeqRecord import SeqRecord"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading sequence file of RosettaFold training set**\n",
        "\n",
        "This file was created by checking the date of the PDB file, RosettaFold was trained on a 100 non-redundant set of the PDB from March 2021."
      ],
      "metadata": {
        "id": "qzRAQzTH2QCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading sequence file of RosettaFold training set\n",
        "!gdown https://drive.google.com/uc?id=1HdsA87s0hDtvMF2xc8BVMOM0wIJocqKN"
      ],
      "metadata": {
        "id": "4Jq8RIJQLoSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check if PDB ID is in training list**\n",
        "\n",
        "If this function returns True that means that the exact PDB was seen in the training set of RoseTTAFold-AllAtom. This means that prediction of the structure will be essentially memorisation."
      ],
      "metadata": {
        "id": "u2CfO9B52jdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_pdb_in_training_set(pdb_id: str) -> bool:\n",
        "    \"\"\"This function checks whether PDB is seen in the training set of RoseTTAFold-AllAtom.\n",
        "    Args:\n",
        "        pdb_id: 4 letter accession code e.g. 3PWH\n",
        "    Returns:\n",
        "        bool, True if pdb seen in training set.\n",
        "    \"\"\"\n",
        "    for record in SeqIO.parse('/content/rosettafold_pdb_seqres.txt', \"fasta\"):\n",
        "        if record.id[1:].upper().startswith(pdb_id.upper()):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "check_pdb_in_training_set('7LPS')"
      ],
      "metadata": {
        "id": "QVkC3i3N1N0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download fasta file for PDB of interest**"
      ],
      "metadata": {
        "id": "uWNLGwio__iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_pdb_fasta(pdb_id: str) -> None | str:\n",
        "    \"\"\" Downloads the FASTA sequence for a given PDB ID and saves it to a file.\n",
        "    Args:\n",
        "    - pdb_id (str): The PDB ID of the protein (4 characters).\n",
        "    Returns:\n",
        "        string of filename (e.g. 1A2B.fasta)\n",
        "    \"\"\"\n",
        "    # Convert the PDB ID to uppercase\n",
        "    pdb_id = pdb_id.upper()\n",
        "    # RCSB PDB URL to fetch the FASTA sequence for the given PDB ID\n",
        "    url = f\"https://www.rcsb.org/fasta/entry/{pdb_id}\"\n",
        "    # Send a GET request to the PDB website to fetch the FASTA sequence\n",
        "    response = requests.get(url)\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Save the FASTA content to the specified output file\n",
        "        output_file = f'{pdb_id}.fasta'\n",
        "        with open(output_file, 'w') as fasta_file:\n",
        "            fasta_file.write(response.text)\n",
        "        print(f\"FASTA sequence for PDB ID {pdb_id} saved to {output_file}.\")\n",
        "        return output_file\n",
        "    print(f\"Failed to retrieve FASTA for PDB ID {pdb_id}. HTTP Status Code: {response.status_code}\")\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "fasta_file = download_pdb_fasta(\"7LPS\")"
      ],
      "metadata": {
        "id": "lsGwWlVr7zLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split fasta file by chain**"
      ],
      "metadata": {
        "id": "Y6EJkgx7AWTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_fasta_by_chains(fasta_file: str) -> list[str]:\n",
        "    \"\"\" This function takes the fasta file from the PDB and split into separate fasta files per chain\n",
        "    Args:\n",
        "        fasta_file: Filename and path of input to be split\n",
        "    Returns:\n",
        "        List of fasta file paths for each chain.\n",
        "    \"\"\"\n",
        "    with open(fasta_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    chain_sequences = {}\n",
        "    for line in lines:\n",
        "        if line.startswith(\">\"):  # Header line\n",
        "            header = line.strip()\n",
        "            chains = [c.strip() for c in header.split('|')[1].replace(\"Chains\", \"\").split(',')]\n",
        "            for chain in chains:\n",
        "                chain_sequences[chain] = [header]\n",
        "        else:\n",
        "            for chain in chains:\n",
        "                chain_sequences[chain].append(line.strip())\n",
        "    output_files = []\n",
        "    for chain, seq_lines in chain_sequences.items():\n",
        "        fname = f\"{Path(fasta_file).stem}_{chain}.fasta\"\n",
        "        output_files.append(fname)\n",
        "        sequence = ''.join(seq_lines[1:])  # Combine sequence lines\n",
        "        split_sequence = [sequence[i:i+60] for i in range(0, len(sequence), 60)]  # Split into 60-char lines\n",
        "        with open(fname, 'w') as out_file:\n",
        "            out_file.write(f\"{seq_lines[0]}\\n\")  # Write header\n",
        "            out_file.write('\\n'.join(split_sequence) + '\\n')  # Write sequence in 80-char lines\n",
        "    return output_files\n",
        "\n",
        "chain_fasta_files = split_fasta_by_chains(fasta_file)"
      ],
      "metadata": {
        "id": "822clLDG9haw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These are the PDB chain fasta files, we can only run one at once**"
      ],
      "metadata": {
        "id": "SS8EdS_Y05QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_fasta_files)"
      ],
      "metadata": {
        "id": "gg1wURlveL-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick which chain you want from list above. Remember python is zero indexed (i.e. counting starts from zero)\n",
        "query_fasta_file = chain_fasta_files[4]"
      ],
      "metadata": {
        "id": "bdqYob_qeOL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we need to check if query sequence is anything like any of the sequences in RoseTTAFoldAllAtom training set. We use phmmer a tool akin to blastp to quickly find results.**"
      ],
      "metadata": {
        "id": "Ii_fdl083X3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_phmmer_results(input_file: str) -> pd.DataFrame:\n",
        "    \"\"\" Takes results from phmmer and returns a dataframe\n",
        "    Args:\n",
        "        input_file: output tblout from phmmer\n",
        "    Returns:\n",
        "        DataFrame with 2 columns: PDB_ID, e_value\n",
        "    \"\"\"\n",
        "    with open(input_file) as f:\n",
        "        readlines = f.readlines()\n",
        "    readlines = [line for line in readlines if not line.startswith('#')]\n",
        "    e_values: list[float] = []\n",
        "    pdb_ids: list[str] = []\n",
        "    for line in readlines:\n",
        "        split_line = line.split()\n",
        "        e_values.append(float(split_line[4]))\n",
        "        pdb_ids.append(split_line[0][1:])\n",
        "    df = pd.DataFrame()\n",
        "    df['PDB_ID'] = pdb_ids\n",
        "    df['e_value'] = e_values\n",
        "    return df\n",
        "\n",
        "\n",
        "def run_phmmer(query_fasta_file: str, seq_db: str, output_dir: str = tempfile.mkdtemp()) -> pd.DataFrame:\n",
        "    \"\"\" Runs phmmer on a query fasta file returns dataframe of results\n",
        "    Args:\n",
        "        query_fasta_file: input fasta file to use as query search\n",
        "        output_dir: where to save data, defaults to temp folder\n",
        "        seq_db: sequence file to screen against\n",
        "    Returns:\n",
        "        DataFrame with 2 columns: PDB_ID, e_value\n",
        "    \"\"\"\n",
        "    output_file = os.path.join(\n",
        "        output_dir, f'{Path(query_fasta_file).stem}_{Path(seq_db).stem}.tab',\n",
        "    )\n",
        "    run_file = os.path.join(output_dir, 'run_file.txt')\n",
        "    subprocess.run([\n",
        "        'phmmer', '--noali', '--tblout', output_file,\n",
        "        '-o', run_file, query_fasta_file, seq_db,\n",
        "    ])\n",
        "    df = process_phmmer_results(output_file)\n",
        "    os.remove(run_file)\n",
        "    os.remove(output_file)\n",
        "    return df\n",
        "\n",
        "df = run_phmmer(query_fasta_file=query_fasta_file, seq_db = '/content/rosettafold_pdb_seqres.txt', output_dir='/content/')"
      ],
      "metadata": {
        "id": "ispTXQer_jbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Once we've found similar proteins in the training set, we will want to grab their sequences so we can do a MSA.**"
      ],
      "metadata": {
        "id": "62QHJ8Mj3nYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_off_target_seqs(ids: list[str]) -> list[SeqRecord]:\n",
        "    \"\"\"Finds off target sequences from their id\n",
        "    Args:\n",
        "        Input list of ids from phmmer.\n",
        "    Returns:\n",
        "        List of Biopython SeqRecord for each off target record found\n",
        "    \"\"\"\n",
        "    record_list = []\n",
        "    for record in SeqIO.parse('/content/rosettafold_pdb_seqres.txt', \"fasta\"):\n",
        "        if record.id[1:] in match_ids:\n",
        "            record_list.append(record)\n",
        "        if len(record_list) == len(match_ids):\n",
        "            break\n",
        "    return record_list\n",
        "\n",
        "match_ids = df.PDB_ID.to_list()\n",
        "record_list = find_off_target_seqs(match_ids)"
      ],
      "metadata": {
        "id": "9j2eMey8bRRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running an MSA to get sequence identity of each off-target**"
      ],
      "metadata": {
        "id": "yq7cBMnY31Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do quick MSA of results from DF against query sequence and return sequence identity\n",
        "from Bio.Align.Applications import MafftCommandline\n",
        "from Bio import AlignIO\n",
        "\n",
        "def calculate_identity(seq1: str, seq2: str) -> float:\n",
        "    \"\"\" Calculate the percentage of identical positions between two aligned sequences.\n",
        "    Args:\n",
        "        seq1 (str): First sequence (query sequence).\n",
        "        seq2 (str): Second sequence (aligned sequence).\n",
        "    Returns:\n",
        "        identity (float): Percentage of identical positions.\n",
        "    \"\"\"\n",
        "    matches = sum(1 for a, b in zip(seq1, seq2) if a == b and a != '-')\n",
        "    return matches / len(seq1) * 100\n",
        "\n",
        "\n",
        "def run_msa_and_calc_identity(query_fasta: str, sequence_records: list[SeqRecord], msa_output: str = \"aligned.fasta\") -> dict[str, float]:\n",
        "    \"\"\" Perform MSA on a list of SeqRecord sequences with a query sequence and calculate sequence identity.\n",
        "    Args:\n",
        "        query_fasta (str): Path to the query FASTA file.\n",
        "        sequence_records (list): List of SeqRecord objects to be aligned with the query.\n",
        "        msa_output (str): Path to save the aligned MSA output.\n",
        "    Returns:\n",
        "        identity_dict (dict): Dictionary with SeqRecord ids and their identity percentages compared to the query.\n",
        "    \"\"\"\n",
        "    # Write the query and sequences to a temporary FASTA file\n",
        "    with open(\"temp_sequences.fasta\", \"w\") as temp_fasta:\n",
        "        # Write the query sequence\n",
        "        for record in SeqIO.parse(query_fasta, \"fasta\"):\n",
        "            SeqIO.write(record, temp_fasta, \"fasta\")\n",
        "            query_id = record.id  # Save the query ID for reference\n",
        "        # Write each sequence from sequence_records to the temp file\n",
        "        for record in sequence_records:\n",
        "            SeqIO.write(record, temp_fasta, \"fasta\")\n",
        "    # Run MAFFT to perform MSA\n",
        "    mafft_cline = MafftCommandline(input=\"temp_sequences.fasta\")\n",
        "    mafft_cline.set_parameter(\"--auto\", True)  # You can set MAFFT parameters here\n",
        "    stdout, stderr = mafft_cline()\n",
        "    # Write MAFFT output to file\n",
        "    with open(msa_output, \"w\") as aligned_file:\n",
        "        aligned_file.write(stdout)\n",
        "    # Read the alignment output\n",
        "    alignment = AlignIO.read(msa_output, \"fasta\")\n",
        "    # Calculate sequence identity\n",
        "    query_seq = None\n",
        "    identity_dict = {}\n",
        "    # Find the query sequence in the alignment\n",
        "    for record in alignment:\n",
        "        if record.id == query_id:\n",
        "            query_seq = str(record.seq)\n",
        "            break\n",
        "    # Compare query sequence with each aligned sequence and calculate sequence identity\n",
        "    for record in alignment:\n",
        "        if record.id != query_id:\n",
        "            aligned_seq = str(record.seq)\n",
        "            identity = calculate_identity(query_seq, aligned_seq)\n",
        "            identity_dict[record.id[1:]] = round(identity, 3)  # Use SeqRecord id as key\n",
        "    # Clean up temporary file\n",
        "    os.remove(\"temp_sequences.fasta\")\n",
        "    return identity_dict\n",
        "\n",
        "seq_dict = run_msa_and_calc_identity(query_fasta_file, record_list)\n",
        "df['Seq_ID'] = df.PDB_ID.map(seq_dict)"
      ],
      "metadata": {
        "id": "bVhyPZ4AJSuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The results shown as a table**\n",
        "\n",
        "3 columns are found in the table:\n",
        "*   PDB_ID is the PDB ID + Chain of the similar protein found in the training set\n",
        "*   e_value is the signficance value of the phmmer search.\n",
        "*   Seq_ID is the sequence identity of the query vs the protein found in the training set expressed as a %. Above 70% is very high sequence similarity. Above 30-40% indicate it is likely to have the same overall fold or be in the same superfamily."
      ],
      "metadata": {
        "id": "Ou8_26Du38iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "vhaBuPMvsZZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j_cXdQNoza3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}